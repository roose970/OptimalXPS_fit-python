{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"font-family: Arial; font-size:4.4em;color:#FFBF00;\"> Optimal XPS fit </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyrights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis performed by \n",
    "\n",
    "Measurements performed by ... at ... \n",
    "\n",
    "Supervised by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on FAIR principle:\n",
    "\n",
    "    For the scientific transparency and verification of results obtained and commmunicated to the public after using a modified version of this work, You (as the recipient of the source code and author of this modified version, used to produce the published results in scientific communications) commit to make this modified source code available in a repository that is easily and freely accessible for a duration of five years after the communication of the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Optimal XPS fit copyrights</font>\n",
    "\n",
    "Copyright &copy; 2023  Antoine Roose\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <https://www.gnu.org/licenses/>. \n",
    "\n",
    "Personal email: roose.devresearcher@gmail.com\n",
    "\n",
    "Github : <a href=\"https://github.com/roose970\">roose970</a>\n",
    "\n",
    "Special thanks to:\n",
    "- Thorsten Bartels-Rausch (Paul Scherrer Institut - Switzerland)\n",
    "- Juan Florez Ospina (Paul Scherrer Institut - Switzerland)\n",
    "- Markus Ammann (Paul Scherrer Institut - Switzerland)\n",
    "- Luca Artiglia (Paul Scherrer Institut - Switzerland)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this notebook, it requires to know first how to handle Jupyter notebook and to have some basics knowledge of python. \n",
    "\n",
    "The readme file and manual are good references to know where to start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of package \n",
    "\n",
    "#Base package\n",
    "import pandas as pd #Handling of datafrane\n",
    "import numpy as np #Mathematical function\n",
    "import matplotlib.pyplot as plt #ploting the results\n",
    "import matplotlib.gridspec as gridspec #Grid to plot multiple graph on the same figure, used for report figures\n",
    "\n",
    "#packages used for XPS analysis\n",
    "import nmrglue \n",
    "from nmrglue import lineshapes1d as ls #use to get nice pseudovoigt function\n",
    "\n",
    "import lmfit #Fitting package\n",
    "from lmfit.models import Model #function to create model to fit\n",
    "from lmfit import minimize #fitting algorithm\n",
    "\n",
    "#Package to handle datafiles\n",
    "from igor.binarywave import load as loadibw #read Igor binary files .ibw provided by the analyzer \n",
    "import h5py #generate and handle HDF5 file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for igor extraction\n",
    "import os.path\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from pprint import pformat\n",
    "\n",
    "import click\n",
    "\n",
    "\n",
    "def save_to_file(content, filepath, mode=\"x\",\n",
    "                 csv_headers=False, json_mini=False):\n",
    "    \"\"\"'Safe' interactive file saver - content should be a dict or string\"\"\"\n",
    "    # Get the extension\n",
    "    ext = os.path.splitext(filepath)[1]\n",
    "\n",
    "    # Write the contents of the file, or ask for alternative filename\n",
    "    try:\n",
    "        with open(filepath, mode) as outfile:\n",
    "            if ext == \".json\":\n",
    "                ind = None if json_mini else 4\n",
    "                json.dump(content, outfile, indent=ind, sort_keys=True)\n",
    "            elif ext in {\".csv\", \".tsv\"}:\n",
    "                _delimiter = \",\" if ext == \".csv\" else \"\\t\"\n",
    "                csvwriter = csv.writer(outfile, delimiter=_delimiter,\n",
    "                                       quotechar='\"',\n",
    "                                       quoting=csv.QUOTE_NONNUMERIC)\n",
    "                if csv_headers:\n",
    "                    csvwriter.writerow(content[\"labels\"])\n",
    "                for line in content[\"data\"]:\n",
    "                    csvwriter.writerow(line)\n",
    "            else:\n",
    "                outfile.write(content)\n",
    "    except FileExistsError:\n",
    "        click.secho(\"\\n{} already exists!\".format(filepath), fg=\"yellow\")\n",
    "        if input(\"Do you want to overwrite it? (y/N): \").lower() == \"y\":\n",
    "            save_to_file(content, filepath, mode=\"w\",\n",
    "                         csv_headers=csv_headers, json_mini=json_mini)\n",
    "        else:\n",
    "            resp = input(\"Rename or cancel? (r/C): \")\n",
    "            if resp == \"r\":\n",
    "                new_filename = input(\"New filename ({}): \".format(ext))\n",
    "                directory = os.path.dirname(filepath)\n",
    "                new_filepath = os.path.join(directory, new_filename + ext)\n",
    "                save_to_file(content, new_filepath, mode=\"x\",\n",
    "                             csv_headers=csv_headers, json_mini=json_mini)\n",
    "            else:\n",
    "                click.secho(\"File not saved\", fg=\"red\")\n",
    "\n",
    "\n",
    "def process_notes(notes):\n",
    "    \"\"\"Splits a byte string into an dict\"\"\"\n",
    "    # Decode to UTF-8, split at carriage-return, and strip whitespace\n",
    "    note_list = list(map(str.strip, notes.decode(errors='ignore').split(\"\\r\")))\n",
    "    note_dict = dict(map(fill_blanks, [p.split(\":\") for p in note_list]))\n",
    "\n",
    "    # Remove the empty string key if it exists\n",
    "    try:\n",
    "        del note_dict[\"\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return note_dict\n",
    "\n",
    "\n",
    "def fill_blanks(lst):\n",
    "    \"\"\"Convert a list (or tuple) to a 2 element tuple\"\"\"\n",
    "    try:\n",
    "        return (lst[0], from_repr(lst[1]))\n",
    "    except IndexError:\n",
    "        return (lst[0], \"\")\n",
    "\n",
    "\n",
    "def from_repr(s):\n",
    "    \"\"\"Get an int or float from its representation as a string\"\"\"\n",
    "    # Strip any outside whitespace\n",
    "    s = s.strip()\n",
    "    # \"NaN\" and \"inf\" can be converted to floats, but we don't want this\n",
    "    # because it breaks in Mathematica!\n",
    "    if s[1:].isalpha():  # [1:] removes any sign\n",
    "        rep = s\n",
    "    else:\n",
    "        try:\n",
    "            rep = int(s)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                rep = float(s)\n",
    "            except ValueError:\n",
    "                rep = s\n",
    "    return rep\n",
    "\n",
    "\n",
    "def pprint(data):\n",
    "    \"\"\"\n",
    "    Format things into lines to get nicer printing\n",
    "    Function is taken from https://github.com/wking/igor/test/test.py\"\"\"\n",
    "    lines = pformat(data).splitlines()\n",
    "    print('\\n'.join([line.rstrip() for line in lines]))\n",
    "\n",
    "\n",
    "def flatten(lst):\n",
    "    \"\"\"Completely flatten an arbitrarily-deep list\"\"\"\n",
    "    return list(_flatten(lst))\n",
    "\n",
    "\n",
    "def _flatten(lst):\n",
    "    \"\"\"Generator for flattening arbitrarily-deep lists\"\"\"\n",
    "    for item in lst:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            yield from _flatten(item)\n",
    "        elif item not in (None, \"\", b''):\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openibw : Function to read XPS files\n",
    "def openibw(FilenameIgor):\n",
    "    RawIgor=loadibw(FilenameIgor)\n",
    "    dataIgor= RawIgor['wave']\n",
    "    \n",
    "    # Get the data numpy array and convert to a simple list\n",
    "    wData = np.nan_to_num(dataIgor['wData']).tolist()\n",
    "    \n",
    "    # Get the labels and tidy them up into a list\n",
    "    labels = list(map(bytes.decode,flatten(dataIgor['labels'])))\n",
    "\n",
    "    # Get the notes and process them into a dict\n",
    "    notes = process_notes(dataIgor['note'])\n",
    "\n",
    "    #compute KE scale from data\n",
    "    dataIgorheader=dataIgor['wave_header']\n",
    "    Elow=dataIgorheader['sfB'][0]\n",
    "    Estep=dataIgorheader['sfA'][0]\n",
    "    Nstep=dataIgorheader['nDim'][0]\n",
    "    Ehigh=Elow+Estep*(Nstep)\n",
    "    Nint=dataIgorheader['nDim'][1]\n",
    "    KE=[np.arange(Elow,Ehigh,Estep)]\n",
    "    \n",
    "    #assemble KE and counts\n",
    "    Spectra=[0.0 for i in range(Nstep)]\n",
    "\n",
    "    for i in range(Nstep):\n",
    "        tempdat=[]\n",
    "        if dataIgorheader['nDim'][2]!=0:\n",
    "            for j in range(Nint):\n",
    "                tempdat=tempdat+wData[i][j]\n",
    "        else:\n",
    "            tempdat=tempdat+wData[i]\n",
    "        Spectra[i]=[np.round(KE[0][i],1)]+tempdat\n",
    "    \n",
    "    #Reshuffling for temporality\n",
    "    Spectratemp=pd.DataFrame(Spectra).rename({0: 'KE'}, axis=1)\n",
    "    dfSpectra=Spectratemp.copy()\n",
    "    n=1\n",
    "    for i in range(dataIgorheader['nDim'][2]):\n",
    "        for j in range(dataIgorheader['nDim'][1]):\n",
    "            dfSpectra[n]=Spectratemp[(j)*(dataIgorheader['nDim'][2])+(i+1)]\n",
    "            n+=1\n",
    "    \n",
    "    return dfSpectra,notes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shirley_calculate : definition of the shirley background. The min and max intensity are set by hand and can be fitted\n",
    "\n",
    "def shirley_calculate(x, y, Imin=0.0, Imax=0.0, tol=1e-5, maxit=10):\n",
    "# https://github.com/kaneod/physics/blob/master/python/specs.py\n",
    " \n",
    "\t# Make sure we've been passed arrays and not lists.\n",
    "\t#x = array(x)\n",
    "\t#y = array(y)\n",
    "\n",
    "\t# Sanity check: Do we actually have data to process here?\n",
    "\t#print(any(x), any(y), (any(x) and any(y)))\n",
    "\tif not (any(x) and any(y)):\n",
    "\t\tprint(\"One of the arrays x or y is empty. Returning zero background.\")\n",
    "\t\treturn x * 0\n",
    "\n",
    "\t# Next ensure the energy values are *decreasing* in the array,\n",
    "\t# if not, reverse them.\n",
    "\tif x[0] < x[-1]:\n",
    "\t\tis_reversed = True\n",
    "\t\tx = x[::-1]\n",
    "\t\ty = y[::-1]\n",
    "\telse:\n",
    "\t\tis_reversed = False\n",
    "\n",
    "\t# Locate the biggest peak.\n",
    "\tmaxidx = abs(y - y.max()).argmin()\n",
    "\t\n",
    "\t# It's possible that maxidx will be 0 or -1. If that is the case,\n",
    "\t# we can't use this algorithm, we return a zero background.\n",
    "\tif maxidx == 0 or maxidx >= len(y) - 1:\n",
    "\t\tprint(\"Boundaries too high for algorithm: returning a zero background.\")\n",
    "\t\treturn x * 0\n",
    "\t\n",
    "\t# Locate the minima either side of maxidx.\n",
    "\tlmidx = abs(y[0:maxidx] - y[0:maxidx].min()).argmin()\n",
    "\trmidx = abs(y[maxidx:] - y[maxidx:].min()).argmin() + maxidx\n",
    "\n",
    "\txl = x[lmidx]\n",
    "\tyl = Imin\n",
    "\txr = x[rmidx]\n",
    "\tyr = Imax\n",
    "\t\n",
    "\t# Max integration index\n",
    "\timax = rmidx - 1\n",
    "\t\n",
    "\t# Initial value of the background shape B. The total background S = yr + B,\n",
    "\t# and B is equal to (yl - yr) below lmidx and initially zero above.\n",
    "\tB = y * 0\n",
    "\tB[:lmidx] = yl - yr\n",
    "\tBnew = B.copy()\n",
    "\t\n",
    "\tit = 0\n",
    "\twhile it < maxit:\n",
    "\t\t# Calculate new k = (yl - yr) / (int_(xl)^(xr) J(x') - yr - B(x') dx')\n",
    "\t\tksum = 0.0\n",
    "\t\tfor i in range(lmidx, imax):\n",
    "\t\t\tksum += (x[i] - x[i + 1]) * 0.5 * (y[i] + y[i + 1] - 2 * yr - B[i] - B[i + 1])\n",
    "\t\tk = (yl - yr) / ksum\n",
    "\t\t# Calculate new B\n",
    "\t\tfor i in range(lmidx, rmidx):\n",
    "\t\t\tysum = 0.0\n",
    "\t\t\tfor j in range(i, imax):\n",
    "\t\t\t\tysum += (x[j] - x[j + 1]) * 0.5 * (y[j] + y[j + 1] - 2 * yr - B[j] - B[j + 1])\n",
    "\t\t\tBnew[i] = k * ysum\n",
    "\t\t# If Bnew is close to B, exit.\n",
    "\t\t#if norm(Bnew - B) < tol:\n",
    "\t\tB = Bnew - B\n",
    "\t\t#print(it, (B**2).sum(), tol**2)\n",
    "\t\tif (B**2).sum() < tol**2:\n",
    "\t\t\tB = Bnew.copy()\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tB = Bnew.copy()\n",
    "\t\tit += 1\n",
    "\n",
    "\t#if it >= maxit:\n",
    "\t\t#print(\"Max iterations exceeded before convergence.\")\n",
    "\tif is_reversed:\n",
    "\t\t#print(\"Shirley BG: tol (ini = \", tol, \") , iteration (max = \", maxit, \"): \", it)\n",
    "\t\treturn (yr + B)[::-1]\n",
    "\telse:\n",
    "\t\t#print(\"Shirley BG: tol (ini = \", tol, \") , iteration (max = \", maxit, \"): \", it)\n",
    "\t\treturn yr + B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speak : definition of S orbital peak \n",
    "#Normalized pseudo voigt function created with ls.sim_pvoigt_fwhm functions scaled by the area\n",
    "\n",
    "def speak(x,BE,FWHM,Area,GL):\n",
    "    return ls.sim_pvoigt_fwhm(x, BE, FWHM, GL)*Area\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppeak : definition of P orbital peak \n",
    "#Sum of normalized pseudo voigt function created with ls.sim_pvoigt_fwhm functions scaled by the area with proportion 2/3 and 1/3\n",
    "\n",
    "def ppeak(x,BE,FWHM,Area,GL,SOC=0.0):\n",
    "    pvoigt1=ls.sim_pvoigt_fwhm(x, BE, FWHM, GL)*2/3*Area\n",
    "    pvoigt2=ls.sim_pvoigt_fwhm(x, BE+SOC, FWHM, GL)*1/3*Area\n",
    "\n",
    "    return pvoigt1+pvoigt2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpeak : definition of D orbital peak \n",
    "#Sum of normalized pseudo voigt function created with ls.sim_pvoigt_fwhm functions scaled by the area with proportion 3/5 and 2/5\n",
    "\n",
    "def dpeak(x,BE,FWHM,Area,GL,SOC=0.0):\n",
    "    pvoigt1=ls.sim_pvoigt_fwhm(x, BE, FWHM, GL)*3/5*Area\n",
    "    pvoigt2=ls.sim_pvoigt_fwhm(x, BE+SOC, FWHM, GL)*2/5*Area\n",
    "\n",
    "    return pvoigt1+pvoigt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liq3a1 : definition of 3a1 orbital for liquid phase water\n",
    "def liq3a1(x,BE,FWHM,Area,GL,splitting=0.0):\n",
    "    pvoigt1=ls.sim_pvoigt_fwhm(x, BE, FWHM, GL)*Area/2\n",
    "    pvoigt2=ls.sim_pvoigt_fwhm(x, BE+splitting, FWHM, GL)*Area/2\n",
    "\n",
    "    return pvoigt1+pvoigt2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspeak : definition of assymetric S orbital peak \n",
    "#http://www.casaxps.com/help_manual/line_shapes.htm\n",
    "#Exponential Asymmetric Blend Based upon Voigt-type Line-Shapes (using sum pseudovoigt function)\n",
    "\n",
    "def Aspeak(x,BE,FWHM,Area,GL,k=0.0):\n",
    "    result=[ls.sim_pvoigt_fwhm(x[i], BE, FWHM, GL)*Area for i in range(len(x))]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i]>=BE:\n",
    "            result[i]=result[i]+(1-ls.sim_pvoigt_fwhm(x[i], BE, FWHM, GL))*np.exp(-k*(x[i]-BE)/FWHM)*Area\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeak : definition of assymetric P orbital peak \n",
    "#http://www.casaxps.com/help_manual/line_shapes.htm\n",
    "#Exponential Asymmetric Blend Based upon Voigt-type Line-Shapes (using sum pseudovoigt function)\n",
    "\n",
    "def Appeak(x,BE,FWHM,Area,GL,SOC,k=0.0):\n",
    "    result=[ls.sim_pvoigt_fwhm(x[i], BE, FWHM, GL)*2/3*Area+ls.sim_pvoigt_fwhm(x[i]+SOC, BE, FWHM, GL)*1/3*Area for i in range(len(x))]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i]>=BE:\n",
    "            result[i]=result[i]+(1-ls.sim_pvoigt_fwhm(x[i], BE, FWHM, GL))*np.exp(-k*(x[i]-BE)/FWHM)*2/3*Area+(1-ls.sim_pvoigt_fwhm(x[i]+SOC, BE, FWHM, GL))*np.exp(-k*(x[i]-BE)/FWHM)*1/3*Area\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adpeak : definition of assymetric D orbital peak \n",
    "#http://www.casaxps.com/help_manual/line_shapes.htm\n",
    "#Exponential Asymmetric Blend Based upon Voigt-type Line-Shapes (using sum pseudovoigt function)\n",
    "\n",
    "def Adpeak(x,BE,FWHM,Area,GL,SOC,k=0.0):\n",
    "    result=[ls.sim_pvoigt_fwhm(x[i], BE, FWHM, GL)*3/5*Area+ls.sim_pvoigt_fwhm(x[i]+SOC, BE, FWHM, GL)*2/5*Area for i in range(len(x))]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i]>=BE:\n",
    "            result[i]=result[i]+(1-ls.sim_pvoigt_fwhm(x[i], BE, FWHM, GL))*np.exp(-k*(x[i]-BE)/FWHM)*3/5*Area+(1-ls.sim_pvoigt_fwhm(x[i]+SOC, BE, FWHM, GL))*np.exp(-k*(x[i]-BE)/FWHM)*2/5*Area\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to implement a longer list of random color for graphs. colors variable is names colors\n",
    "from random import randint\n",
    "colors = []\n",
    "for i in range(200):    \n",
    "    colors.append('#%06X' % randint(0, 0xFFFFFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrum_check : Function to plot a report figure of the raw data to determine if some spectra has to be removed\n",
    "\n",
    "def Spectrum_check(specdatabase,removed):\n",
    "    col_names=specdatabase.columns\n",
    "    modifieddata=specdatabase.copy().drop(labels=removed,axis=1)\n",
    "    modifiedcol_names=modifieddata.columns\n",
    "    averageddata=modifieddata.iloc[0:,1:].mean(axis=1)\n",
    "    stddata=modifieddata.iloc[0:,1:].std(axis=1)\n",
    "\n",
    "    ###############################\n",
    "    plt.figure(figsize=(20,18))\n",
    "    G=gridspec.GridSpec(3,10)\n",
    "\n",
    "    #Stack graph\n",
    "    offset=0.0\n",
    "    axes_1 = plt.subplot(G[0:2,0:3])\n",
    "    for i in range(1,len(modifiedcol_names)):\n",
    "        axes_1.plot(modifieddata[modifiedcol_names[0]],modifieddata[modifiedcol_names[i]],label=modifiedcol_names[i],color=colors[modifiedcol_names[i]])\n",
    "    axes_1.errorbar(modifieddata[modifiedcol_names[0]],averageddata,yerr=stddata,label='Average',linewidth=4.0,color='black')\n",
    "    axes_1.set_xlabel('KE (eV)')\n",
    "    axes_1.set_ylabel('Counts (A.U.)')\n",
    "    axes_1.legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.55, 0, 0), ncol = 5)\n",
    "\n",
    "    #Contour plot\n",
    "    axes_2 = plt.subplot(G[:2,4:10])\n",
    "    delta=np.round(round(specdatabase[col_names[0]][1],1)-round(specdatabase[col_names[0]][0],1),1)\n",
    "    X=np.arange(round(specdatabase[col_names[0]][0],1),round(specdatabase[col_names[0]][specdatabase.index[-1]],1)+delta,delta)\n",
    "    Y=np.arange(0,len(range(1,len(col_names)))+1)\n",
    "    x,y=np.meshgrid(X,Y)\n",
    "    Z=np.transpose(specdatabase.iloc[0:,1:].values.flatten().reshape(len(specdatabase.iloc[0:,1:].values),len(Y)-1)) #reshape with len(specdatabase.iloc[0:,1:].values) as first values avoid a bug but does not know why yet such a bug appears\n",
    "    axes_2.pcolormesh(x+(delta/2),y+0.5,Z, vmin=np.min(Z), vmax=np.max(Z), shading='auto')\n",
    "    axes_2.set_yticks(Y, minor=True)\n",
    "    axes_2.grid(which='both',axis='y',linestyle='-.',alpha=0.3)\n",
    "    axes_2.set_xlabel('KE (eV)')\n",
    "    axes_2.set_ylabel('Spectrum')\n",
    "\n",
    "    #Line profile\n",
    "    axes_3 = plt.subplot(G[2:,4:10])\n",
    "    sumval=specdatabase.iloc[0:,1:].sum(axis=0)\n",
    "    axes_3.plot(np.arange(1,len(range(1,len(col_names)))+1), sumval)\n",
    "    axes_3.set_xlabel('Spectrum')\n",
    "    axes_3.set_ylabel('Sum counts (A.U.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful function that would need some user's hand modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to allow the fitting of reference spectra into another. The reference spectra is transformed into a model with this function.\n",
    "# The user has to modified the function name and the dataset variables to implement the reference spectra he has previously uploaded\n",
    " \n",
    "def set_your_funcion_name(x,y,shift=0.0,scale=1):\n",
    "    #the function take to parameter to be fit, 'shift' to take into account any possible shift in kinetic energy, 'scale' to allow the scaling of intensity.\n",
    "    #parameter x and y are data from the spectra to fit (independent variables)\n",
    "\n",
    "    global set_your_dataframe_name #here write the name of the dataframe that contain the average spectra\n",
    "\n",
    "    ydata=y.copy()\n",
    "    \n",
    "    for i in range(len(ydata)):\n",
    "        if (set_your_dataframe_name.loc[set_your_dataframe_name['BE']==(np.round(x[i]+shift,1))].empty==False):\n",
    "            ydata[i]=set_your_dataframe_name['Counts'].loc[set_your_dataframe_name['BE']==(np.round(x[i]+shift,1))].values\n",
    "            ydata[i]=ydata[i]*scale\n",
    "        \n",
    "\n",
    "    return ydata\n",
    "\n",
    "#to call the function as a model in the cell to create nodel the user has to use the following commands:\n",
    "# peakname=Model(set_your_function_name,independent_vars=['x','y'],prefix='peakname_')\n",
    "# and set/modify the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!START OF THE ANALYSIS HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtitle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open file, read and store data/metadata\n",
    "\n",
    "################################################################################################################\n",
    "dat1,info1=openibw(r\"yourpathway\\yourfilename.ibw\") #chage filename and variable name according to what is needed\n",
    "#the variable name should be consistent then with the following cells\n",
    "dat1_hv=Your_photon_energy #change the photon energy\n",
    "################################################################################################################\n",
    "\n",
    "#comment/uncomment next section as you need\n",
    "#print(dat1) #print data\n",
    "#print(info1) #print metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all spectra to check that there is no spectrum outstanding\n",
    "\n",
    "dat1_removed=[] #add here the numbers of the spectra you want to remove to take a full range # [i for i in range(low,high)] careful the first speactrum index is 1\n",
    "Spectrum_check(dat1,dat1_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average and standard deviation computation\n",
    "\n",
    "tempdata=dat1.copy().drop(labels=dat1_removed,axis=1)\n",
    "tempRawspectra=tempdata.iloc[0:,1:].mean(axis=1)\n",
    "tempstdRawspectra=tempdata.iloc[0:,1:].std(axis=1)\n",
    "\n",
    "tempBE=dat1_hv-dat1['KE']\n",
    "\n",
    "\n",
    "Rawspectra=pd.concat([tempBE,tempRawspectra,tempstdRawspectra],axis=1)\n",
    "Rawspectra.columns=['BE','Counts','std']\n",
    "\n",
    "#plot spectra\n",
    "graph,axis=plt.subplots(1)\n",
    "axis.plot(Rawspectra['BE'],Rawspectra['Counts'])\n",
    "axis.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "UpperBE=the_upper_BE\n",
    "LowerBE=the_lower_BE\n",
    "################################################################\n",
    "\n",
    "#change variable name of rawspectra\n",
    "raw1=Rawspectra.loc[Rawspectra['BE']<=UpperBE].copy()\n",
    "raw2=raw1.loc[raw1['BE']>=LowerBE].copy()\n",
    "\n",
    "\n",
    "#Change variable name Ibeg and Iend\n",
    "################################################################\n",
    "Ibeg=raw2.iloc[0].name\n",
    "Iend=raw2.iloc[-1].name\n",
    "################################################################\n",
    "\n",
    "#print(Ibeg)\n",
    "#print(Iend)\n",
    "\n",
    "#uncomment if you want to plot the average spectra again\n",
    "#plot the graph\n",
    "# graph,axis=plt.subplots(1)\n",
    "# axis.plot(Rawspectra['BE'],Rawspectra['Counts'])\n",
    "# axis.invert_xaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the biggest job, set the peaks/background for each spectra\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "#All variable name should be different for each pekas/background and consistent with their prefix (for the user to know what belongs to each peaks\n",
    "# )\n",
    "#Spectrum 1\n",
    "xdatgs1=Rawspectra['BE'][Ibeg:Iend].values  #here set the x values of the spectrum to fit\n",
    "ydatgs1=Rawspectra['Counts'][Ibeg:Iend].values #here set the y value of the spectrum to fit\n",
    "\n",
    "#definition of background\n",
    "#All XPS spectra should get a shirley or a tougaard (not implemented yet) background. And some recent studies shows that fitting the backgrounds with the peaks is more accurate\n",
    "backgs1=Model(shirley_calculate,independent_vars=['x','y','tol','maxit'],prefix='backgs1_') #model for the shirley background\n",
    "pars=backgs1.make_params() #creation of the parameter (should be done only for the first one then use pars.update(your_peakvariable.make_params()) )\n",
    "#once the parameters variable is created, you should assign initial values, and eventually boundary conditions or fixed the variable (with the option vary=False)\n",
    "#to assign values use the command pars['prefix+name_of_the_parameter'].set(value=initialvalue[,min=minvalue,max=maxvalue,vary=False])\n",
    "pars['backgs1_Imin'].set(value=20.0,min=-450.0,max=250) #set the parameter / high binding energy\n",
    "pars['backgs1_Imax'].set(value=0.0,min=-450.0,max=150) #set the parameter / low binding energy\n",
    "\n",
    "#then define your peaks. Below an example of a gas phase VB of water\n",
    "#definition of peaks\n",
    "#peak 1 1b1\n",
    "pgs11=Model(speak,prefix='pgs11_') #model for the dpeak\n",
    "pars.update(pgs11.make_params()) #update the parameter(important to not create a new set of parameter)\n",
    "pars['pgs11_BE'].set(value=13,min=12,max=14) #set the parameter\n",
    "pars['pgs11_FWHM'].set(value=0.4,min=0.0,max=4.0) #set the parameter\n",
    "pars['pgs11_Area'].set(value=5000,min=0.0) #set the parameter\n",
    "pars['pgs11_GL'].set(value=0.001,min=0.0,max=1.0,vary=False) #set the parameter\n",
    "\n",
    "#peak 2 3a1\n",
    "pgs12=Model(speak,prefix='pgs12_') #model for the dpeak\n",
    "pars.update(pgs12.make_params()) #update the parameter(important to not create a new set of parameter)\n",
    "pars['pgs12_BE'].set(value=15.3,min=14,max=17) #set the parameter\n",
    "pars['pgs12_FWHM'].set(value=1.15,min=0.0,max=4.0) #set the parameter\n",
    "pars['pgs12_Area'].set(value=2500,min=0.0) #set the parameter\n",
    "pars['pgs12_GL'].set(value=0.001,min=0.0,max=1.0,vary=False) #set the parameter\n",
    "\n",
    "#peak 3 1b2\n",
    "pgs13=Model(speak,prefix='pgs13_') #model for the dpeak\n",
    "pars.update(pgs13.make_params()) #update the parameter(important to not create a new set of parameter)\n",
    "pars['pgs13_BE'].set(value=19,min=18,max=21) #set the parameter\n",
    "pars['pgs13_FWHM'].set(value=1.6,min=0.0,max=4.0) #set the parameter\n",
    "pars['pgs13_Area'].set(value=1300,min=0.0) #set the parameter\n",
    "pars['pgs13_GL'].set(value=0.001,min=0.0,max=1.0,vary=False) #set the parameter\n",
    "\n",
    "#create model for spectrum, this model is a sum of the backgrounds and the peaks\n",
    "modgs1 = backgs1 + pgs11 + pgs12 + pgs13 #create the sum model for the spectrum\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "#If you want to fit multiple spectra with constrained parameters add as many section to create model as there is spectra to fit.\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "#end of the edition, fitting is close but double check before going to the next cell\n",
    "#debugging this part can be quite difficult the more spectra to fit there is.\n",
    "#Check carefully that the list of parameter (pars in this example) is correctly set and has not been erased by another make_params() command\n",
    "#check that you have correctly set the name of the variables in the cell, otherwise you may have some surprise in the fitting or some code error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data and initial fit to check\n",
    "#The initial fit should be close to the spectra for faster fitting and better results\n",
    "\n",
    "plt.figure(figsize=(6,12))\n",
    "###############################################################################################\n",
    "plt.plot(xdatgs1, ydatgs1) #in these three lines, change the variable name to the name you have set\n",
    "plt.plot(xdatgs1, modgs1.eval(pars,x=xdatgs1,y=ydatgs1, shift=0.0, tol=1e-5, maxit=30), '--m', label='init_fit') #plot initial evaluation of the model created in the cell earlier. This evaluation is based on initial parameter \n",
    "\n",
    "#in case there is more than one spectrum to fit, an offset is added based on the maxvalue of the previous spectrum\n",
    "#offset=np.max(ydatgs1) #offset the next spectra to not overlap\n",
    "# ###############################################################################################\n",
    "\n",
    "#then create as many section as required by adding the new max value to the offset.\n",
    "\n",
    "# ###############################################################################################\n",
    "# plt.plot(xdatgs2, offset+ydatgs2)\n",
    "# plt.plot(xdatgs2, offset+modgs2.eval(pars,x=xdatgs2,y=ydatgs2,shift=0.0, tol=1e-5, maxit=30), '--m')\n",
    "\n",
    "# offset=offset+np.max(ydatgs2) #offset the next spectra to not overlap note that the line is different from the previous offset\n",
    "# ###############################################################################################\n",
    "\n",
    "# #the previous section has to be copy as many time as needed. Don't forget to change the variable names\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of the fitting function\n",
    "\n",
    "#note: lmfit needs a 1D array to work. This function merge all the data, model and residual in one array for the fitting\n",
    "# xaxis values need to be put in one dataset as well\n",
    "\n",
    "data=[] #list initialisation\n",
    "\n",
    "#extend the data variable as many time as there is spectrum\n",
    "##############################################################################################################\n",
    "data.extend(ydatgs1) #creation of the dataset for the fitting function . Change variable names as set previsouly\n",
    "# data.extend(ydatgs2)\n",
    "# data.extend(ydatgs3)\n",
    "# data.extend(ydatgs4)\n",
    "# data.extend(ydatgs5)\n",
    "# data.extend(ydatgs6)\n",
    "# data.extend(ydatgs7)\n",
    "##############################################################################################################\n",
    "\n",
    "data=np.array(data) #convert list to array\n",
    "\n",
    "xaxis=[]\n",
    "\n",
    "#extend the xaxis variable as many time as there is spectrum\n",
    "#################################################################################################################\n",
    "xaxis.append(xdatgs1) #fitting function needs x values as argument for the fitting procedure. change variable names\n",
    "# xaxis.append(xdatgs2)\n",
    "# xaxis.append(xdatgs3)\n",
    "# xaxis.append(xdatgs4)\n",
    "# xaxis.append(xdatgs5)\n",
    "# xaxis.append(xdatgs6)\n",
    "# xaxis.append(xdatgs7)\n",
    "#################################################################################################################\n",
    "\n",
    "xaxis=np.array(xaxis)\n",
    "\n",
    "#create the objective of the fit. the fitting algorithm wants an objective that it will try to set to 0, here the residual\n",
    "def objective(pars, xaxis, data):\n",
    "    \"\"\"Calculate total data residual for fits of models to several data sets.\"\"\"\n",
    "    \n",
    "    res = 0.0*data[:]\n",
    "\n",
    "    mod=[]\n",
    "    \n",
    "    #extend the mod variable as many time as there is spectrum\n",
    "    #######################################################################################################################################\n",
    "    mod.extend(modgs1.eval(pars,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30)) #initialisation of the model. Change variable names as set previsouly\n",
    "    # mod.extend(modgs2.eval(pars,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30))\n",
    "    # mod.extend(modgs3.eval(pars,x=xdatgs3,y=ydatgs3, tol=1e-5, maxit=30))\n",
    "    # mod.extend(modgs4.eval(pars,x=xdatgs4,y=ydatgs4, tol=1e-5, maxit=30))\n",
    "    # mod.extend(modgs5.eval(pars,x=xdatgs5,y=ydatgs5, tol=1e-5, maxit=30))\n",
    "    # mod.extend(modgs6.eval(pars,x=xdatgs6,y=ydatgs6, tol=1e-5, maxit=30))\n",
    "    # mod.extend(modgs7.eval(pars,x=xdatgs7,y=ydatgs7, tol=1e-5, maxit=30))\n",
    "    #######################################################################################################################################\n",
    "\n",
    "    mod=np.array(mod)\n",
    "    \n",
    "    res = data - mod\n",
    "\n",
    "    return res \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting, can be long, go take a moka/tea and read papers :) \n",
    "\n",
    "#change out variable name to not erase answer of a previous fitting in the notebook\n",
    "#decrease ftol and xtol to improve the fitting up to the moment the time is not reasonable enymore (more than an hour is long)\n",
    "#future development will be done to implement likelyhood based methodology (Markov chain monte carlo)\n",
    "outgs1 = minimize(objective, pars, args=(xaxis,data),ftol=1e-5,xtol=1e-5)\n",
    "print(outgs1.message) #message fit succeded or not... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the report\n",
    "lmfit.report_fit(outgs1) #change the variable name accordint to the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a figure to resume the fit results\n",
    "\n",
    "#################################################################################################\n",
    "#according to the number of spectra you may want to edit this section. I may write a short manual\n",
    "#for this purpose. For the moment internet is your friend :)\n",
    "#gridspec and matplotlib webpages are a good start\n",
    "\n",
    "#On this figures I plot on the left the spectra with their initial fit and best fit.\n",
    "#Then, a plot that shows the residuals\n",
    "#and finally one plot per spectrum with all the individual contribution of each peaks (up to four plots then create another cells if there is more spectra)\n",
    "\n",
    "#to change the color, you can refer to the color code at the end of this notebook\n",
    "\n",
    "plt.figure(figsize=(24,12)) #by editing the two number the figure size can be changed\n",
    "G=gridspec.GridSpec(2,10,wspace=0.5,hspace=0.24) #create a virtual grid in the figure\n",
    "\n",
    "#The grid created got 2 vertical section and 10 horizontal ones\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "#plot initial fit and best fit\n",
    "\n",
    "axes_1 = plt.subplot(G[:,0:2]) #plot on both vertical sections and the first two horizontal sections\n",
    "\n",
    "#######################################################################################################\n",
    "#change variable name in this section\n",
    "axes_1.plot(xdatgs1, modgs1.eval(pars,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '--m', label='initial fit')\n",
    "axes_1.plot(xdatgs1, modgs1.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '-k', label='best fit')\n",
    "axes_1.plot(xdatgs1, ydatgs1, label='VB gas phase 250eV') #edit label if needed\n",
    "\n",
    "#an offset is created for the next spectrum \n",
    "offset=np.max(ydatgs1) #offset for the next spectrum\n",
    "#######################################################################################################\n",
    "\n",
    "#copy paste the next session as needed\n",
    "#######################################################################################################\n",
    "# axes_1.plot(xdatgs2, offset+modgs2.eval(pars,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30), '--m')\n",
    "# axes_1.plot(xdatgs2, offset+modgs2.eval(outgs1.params,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30), '-k')\n",
    "# axes_1.plot(xdatgs2, offset+ydatgs2, label='VB gas phase 310eV')\n",
    "\n",
    "#the offset is updated for the next spectrum \n",
    "# offset=offset+np.max(ydatgs2) #offset for the next spectrum\n",
    "#######################################################################################################\n",
    "\n",
    "\n",
    "axes_1.set_xlabel('BE (eV)')\n",
    "axes_1.set_ylabel('Counts (a.u.)')\n",
    "axes_1.legend()\n",
    "axes_1.invert_xaxis() #invert xaxis. standard for BE plot\n",
    "\n",
    "#plot residuals\n",
    "offset=0.0 #reset offset\n",
    "axes_2 = plt.subplot(G[:,2:4],sharey=axes_1) #plot on both vertical sections and the third and fourth horizontal sections #yaxis is the same as the first plot\n",
    "\n",
    "###########################################################################################################################\n",
    "#change variable name in this section. Edit label if needed\n",
    "axes_2.plot(xdatgs1, ydatgs1-modgs1.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '--', label='residual VB gas phase 250eV')\n",
    "axes_2.plot(xdatgs1, ydatgs1-ydatgs1,'b') #just the zero line for a better representation\n",
    "\n",
    "#an offset is created for the next spectrum \n",
    "offset=np.max(ydatgs1) #offset for the next spectrum\n",
    "###########################################################################################################################\n",
    "\n",
    "#copy paste the next session as needed\n",
    "###########################################################################################################################\n",
    "#change variable name in this section. Edit label if needed\n",
    "# axes_2.plot(xdatgs2, offset+ydatgs2-modgs2.eval(outgs1.params,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30), '--', label='residual VB gas phase 310eV')\n",
    "# axes_2.plot(xdatgs1, offset+ydatgs1-ydatgs1,color='orange') #just the zero line with the offset for a better representation\n",
    "\n",
    "#the offset is updated for the next spectrum \n",
    "# offset=offset+np.max(ydatgs2) #offset for the next spectrum\n",
    "###########################################################################################################################\n",
    "\n",
    "axes_2.set_xlabel('BE (eV)')\n",
    "axes_2.set_ylabel('Counts (a.u.)')\n",
    "axes_2.legend()\n",
    "axes_2.invert_xaxis()\n",
    "\n",
    "#plot individual spectrum fitting\n",
    "\n",
    "#DP1\n",
    "axes_3 = plt.subplot(G[0,4:7]) #plot on first vertical section and the fith to seventh horizontal sections \n",
    "##############################################################################################################################\n",
    "#change variable name in this section. Edit label if needed\n",
    "axes_3.plot(xdatgs1, ydatgs1, 'b',label='VB gas phase 250eV')\n",
    "background=backgs1.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30) #get the value of the background\n",
    "#plot each peaks. The background is added for a better representation. Suggestion: peaks should be plotted efore that that they appears first in the legend of the graph\n",
    "axes_3.plot(xdatgs1, background+pgs11.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '--',color='dimgrey', label='1b1')\n",
    "axes_3.plot(xdatgs1, background+pgs12.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '--k', label='3a1')\n",
    "axes_3.plot(xdatgs1, background+pgs13.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '--r', label='1b2')\n",
    "axes_3.plot(xdatgs1, background+pgs14.eval(outgs1.params,x=xdatgs1,y=ydatgs1, tol=1e-5, maxit=30), '--g', label='O2s')\n",
    "#plot the background\n",
    "axes_3.plot(xdatgs1, background, '--m', label='Shirley Background')\n",
    "##############################################################################################################################\n",
    "\n",
    "axes_3.set_xlabel('BE (eV)')\n",
    "axes_3.set_ylabel('Counts (a.u.)')\n",
    "axes_3.legend()\n",
    "axes_3.invert_xaxis()\n",
    "\n",
    "#in case there is more spectrum here is an example of the code to plot up to four spectra\n",
    "#DP2\n",
    "# axes_4 = plt.subplot(G[0,7:]) #plot on first vertical section and the eighth to tenth horizontal sections \n",
    "# ##############################################################################################################################\n",
    "# #change variable name in this section. Edit label if needed\n",
    "# axes_4.plot(xdatgs2, ydatgs2,color='orange', label='VB gas phase 310eV')\n",
    "# background=backgs2.eval(outgs1.params,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30)\n",
    "# axes_4.plot(xdatgs2, background+pgs21.eval(outgs1.params,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30), '--',color='dimgrey', label='1b1')\n",
    "# axes_4.plot(xdatgs2, background+pgs22.eval(outgs1.params,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30), '--k', label='3a1')\n",
    "# axes_4.plot(xdatgs2, background+pgs23.eval(outgs1.params,x=xdatgs2,y=ydatgs2, tol=1e-5, maxit=30), '--r', label='1b2')\n",
    "# axes_4.plot(xdatgs2, background, '--m', label='Shirley Background')\n",
    "# ##############################################################################################################################\n",
    "\n",
    "# axes_4.set_xlabel('BE (eV)')\n",
    "# axes_4.set_ylabel('Counts (a.u.)')\n",
    "# axes_4.legend()\n",
    "# axes_4.invert_xaxis()\n",
    "\n",
    "#DP3\n",
    "# axes_5 = plt.subplot(G[1,4:7]) #plot on second vertical section and the fith to seventh horizontal sections\n",
    "# ##############################################################################################################################\n",
    "# #change variable name in this section. Edit label if needed\n",
    "# axes_5.plot(xdatgs3, ydatgs3,'g', label='VB gas phase 410eV')\n",
    "# background=backgs3.eval(outgs1.params,x=xdatgs3,y=ydatgs3, tol=1e-5, maxit=30)\n",
    "# axes_5.plot(xdatgs3, background+pgs31.eval(outgs1.params,x=xdatgs3,y=ydatgs3, tol=1e-5, maxit=30), '--',color='dimgrey', label='1b1')\n",
    "# axes_5.plot(xdatgs3, background+pgs32.eval(outgs1.params,x=xdatgs3,y=ydatgs3, tol=1e-5, maxit=30), '--k', label='3a1')\n",
    "# axes_5.plot(xdatgs3, background+pgs33.eval(outgs1.params,x=xdatgs3,y=ydatgs3, tol=1e-5, maxit=30), '--r', label='1b2')\n",
    "# axes_5.plot(xdatgs3, background, '--m', label='Shirley Background')\n",
    "# ##############################################################################################################################\n",
    "\n",
    "# axes_5.set_xlabel('BE (eV)')\n",
    "# axes_5.set_ylabel('Counts (a.u.)')\n",
    "# axes_5.legend()\n",
    "# axes_5.invert_xaxis()\n",
    "\n",
    "#DP4\n",
    "# axes_6 = plt.subplot(G[1,7:]) #plot on second vertical section and the eighth to tenth horizontal sections\n",
    "# ##############################################################################################################################\n",
    "# #change variable name in this section. Edit label if needed\n",
    "# axes_6.plot(xdatgs4, ydatgs4,'r', label='VB gas phase 510eV')\n",
    "# background=backgs4.eval(outgs1.params,x=xdatgs4,y=ydatgs4, tol=1e-5, maxit=30)\n",
    "# axes_6.plot(xdatgs4, background+pgs41.eval(outgs1.params,x=xdatgs4,y=ydatgs4, tol=1e-5, maxit=30), '--',color='dimgrey', label='1b1')\n",
    "# axes_6.plot(xdatgs4, background+pgs42.eval(outgs1.params,x=xdatgs4,y=ydatgs4, tol=1e-5, maxit=30), '--k', label='3a1')\n",
    "# axes_6.plot(xdatgs4, background+pgs43.eval(outgs1.params,x=xdatgs4,y=ydatgs4, tol=1e-5, maxit=30), '--r', label='1b2')\n",
    "# axes_6.plot(xdatgs4, background, '--m', label='Shirley Background')\n",
    "# ##############################################################################################################################\n",
    "\n",
    "# axes_6.set_xlabel('BE (eV)')\n",
    "# axes_6.set_ylabel('Counts (a.u.)')\n",
    "# axes_6.legend()\n",
    "# axes_6.invert_xaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='OptimalXPSfit.ipynb' #write filename of the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the jupyter notebook in HTML, save it before activating the cell\n",
    "from nbconvert import HTMLExporter\n",
    "import codecs\n",
    "import nbformat\n",
    "exporter = HTMLExporter()\n",
    "output_notebook = nbformat.read(fileName, as_version=4)\n",
    "output, resources = exporter.from_notebook_node(output_notebook)\n",
    "codecs.open(fileName + '.html', 'w', encoding='utf-8').write(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 file (under development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file=h5py.File('./test_hdf5.hdf5','a')\n",
    "my_group_01 = my_file.create_group('metadata')\n",
    "my_group_02 = my_file.create_group('/metadata/spectra')\n",
    "group_01 = my_file['/metadata']\n",
    "my_dataset = group_01.create_dataset(name='demo_metadataset', data=info1,dtype=)\n",
    "group_02 = my_file['/metadata/spectra']\n",
    "my_dataset2 = group_01.create_dataset(name='demo_dataset', data=dat1)\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color code matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "def plot_colortable(colors, sort_colors=True, emptycols=0):\n",
    "\n",
    "    cell_width = 212\n",
    "    cell_height = 22\n",
    "    swatch_width = 48\n",
    "    margin = 12\n",
    "\n",
    "    # Sort colors by hue, saturation, value and name.\n",
    "    if sort_colors is True:\n",
    "        by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),\n",
    "                         name)\n",
    "                        for name, color in colors.items())\n",
    "        names = [name for hsv, name in by_hsv]\n",
    "    else:\n",
    "        names = list(colors)\n",
    "\n",
    "    n = len(names)\n",
    "    ncols = 4 - emptycols\n",
    "    nrows = n // ncols + int(n % ncols > 0)\n",
    "\n",
    "    width = cell_width * 4 + 2 * margin\n",
    "    height = cell_height * nrows + 2 * margin\n",
    "    dpi = 72\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    fig.subplots_adjust(margin/width, margin/height,\n",
    "                        (width-margin)/width, (height-margin)/height)\n",
    "    ax.set_xlim(0, cell_width * 4)\n",
    "    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        row = i % nrows\n",
    "        col = i // nrows\n",
    "        y = row * cell_height\n",
    "\n",
    "        swatch_start_x = cell_width * col\n",
    "        text_pos_x = cell_width * col + swatch_width + 7\n",
    "\n",
    "        ax.text(text_pos_x, y, name, fontsize=14,\n",
    "                horizontalalignment='left',\n",
    "                verticalalignment='center')\n",
    "\n",
    "        ax.add_patch(\n",
    "            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n",
    "                      height=18, facecolor=colors[name], edgecolor='0.7')\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_colortable(mcolors.BASE_COLORS, sort_colors=False, emptycols=1)\n",
    "plot_colortable(mcolors.TABLEAU_COLORS, sort_colors=False, emptycols=2)\n",
    "plot_colortable(mcolors.CSS4_COLORS)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('Anaconda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
